{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import dateutil.parser as time_parser\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.amp\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader \n",
    "from torch import optim\n",
    "from data_provider.data_factory import data_provider\n",
    "from exp.exp_basic import Exp_Basic\n",
    "from models import FEDformer, Autoformer, Informer, Transformer\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from utils.metrics import metric\n",
    "from utils.timefeatures import time_features\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "something goes wrong with dimensions \n",
    "\n",
    "batch_x: torch.Size([32, 384, 105])\n",
    "\n",
    "batch_y: torch.Size([32, 192, 105])\n",
    "\n",
    "batch_x_mark: torch.Size([32, 384, 6])\n",
    "\n",
    "batch_y_mark: torch.Size([32, 192, 6])\n",
    "\n",
    "dec_inp: torch.Size([32, 144, 105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForgingData(Dataset):\n",
    "    def __init__(self, preload_path=None):\n",
    "        # forecasting task info\n",
    "        self.seq_len = 24 * 4 * 4\n",
    "        self.label_len = 24 * 4\n",
    "        self.pred_len = 24 * 4\n",
    "        \n",
    "        if preload_path:\n",
    "            self.load(preload_path)\n",
    "        else:\n",
    "            self.data = pd.read_csv(\"../../data/timeseries_1month.csv\")\n",
    "            self.data_val = pd.read_csv(\"../../data/timeseries.csv\")\n",
    "            \n",
    "            self.data.drop_duplicates([\"Received Time\"], inplace=True, ignore_index=True)\n",
    "            self.data.drop(columns=[\"Unnamed: 0\"])\n",
    "            self.data_val.drop_duplicates([\"Received Time\"], inplace=True, ignore_index=True)\n",
    "            self.data_val.drop(columns=[\"Unnamed: 0\"])\n",
    "            \n",
    "            # self.data[\"Received Time\"] = self.data[\"Received Time\"].apply(time_parser.parse)\n",
    "            self.data[\"Received Time\"] = pd.to_datetime(self.data[\"Received Time\"], format=\"ISO8601\")\n",
    "            self.data = self.data.set_index(\"Received Time\")\n",
    "            self.data = self.data.resample(\"100ms\").ffill()\n",
    "            self.data.dropna(inplace=True)\n",
    "            self.data = self.data.reset_index()\n",
    "            \n",
    "            # self.data_val[\"Received Time\"] = self.data_val[\"Received Time\"].apply(time_parser.parse)\n",
    "            self.data_val[\"Received Time\"] = pd.to_datetime(self.data_val[\"Received Time\"], format=\"ISO8601\")\n",
    "            self.data_val = self.data_val.set_index(\"Received Time\")\n",
    "            self.data_val = self.data_val.resample(\"100ms\").ffill()\n",
    "            self.data_val.dropna(inplace=True)\n",
    "            self.data_val = self.data_val.reset_index()\n",
    "            \n",
    "            # time features encoded secondly\n",
    "            self.data_stamp = time_features(pd.to_datetime(self.data[\"Received Time\"].values), freq=\"s\")\n",
    "            self.data_stamp_val = time_features(pd.to_datetime(self.data_val[\"Received Time\"].values), freq=\"s\")\n",
    "            self.data_stamp = self.data_stamp.transpose(1, 0)\n",
    "            self.data_stamp_val = self.data_stamp_val.transpose(1, 0)\n",
    "            \n",
    "            self.filter = set()\n",
    "            with open(\"/home/malio/EPICMAP/src/opcua/data_analysis/useless_counters.txt\", \"r\") as f:\n",
    "                to_filter = f.readline()\n",
    "                while to_filter:\n",
    "                    self.filter.add(to_filter.rstrip())\n",
    "                    to_filter = f.readline()\n",
    "            \n",
    "            self.data = self.data.drop(columns=self.filter, errors=\"ignore\")\n",
    "            self.data_val = self.data_val.drop(columns=self.filter, errors=\"ignore\")\n",
    "            \n",
    "            self.data = self.data.drop(columns=[\"Received Time\"], errors=\"ignore\")\n",
    "            self.data_val = self.data_val.drop(columns=[\"Received Time\"], errors=\"ignore\")\n",
    "            \n",
    "            #scaling\n",
    "            self.scaler = StandardScaler()\n",
    "            self.data = self.scaler.fit_transform(self.data)\n",
    "            self.data_val = self.scaler.transform(self.data_val)\n",
    "            \n",
    "            #aliases\n",
    "            self.data_x = self.data\n",
    "            self.data_y = self.data\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "    \n",
    "    def save(self, path):\n",
    "        to_save = {}\n",
    "        to_save[\"data\"] = self.data\n",
    "        to_save[\"data_val\"] = self.data_val\n",
    "        to_save[\"data_stamp\"] = self.data_stamp\n",
    "        to_save[\"data_stamp_val\"] = self.data_stamp_val\n",
    "        to_save[\"filter\"] = self.filter\n",
    "        to_save[\"scaler\"] = self.scaler\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(to_save, f, protocol=4)\n",
    "    \n",
    "    def load(self, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            to_load = pickle.load(f)\n",
    "            self.data = to_load[\"data\"]\n",
    "            self.data_val = to_load[\"data_val\"]\n",
    "            self.data_stamp = to_load[\"data_stamp\"]\n",
    "            self.data_stamp_val = to_load[\"data_stamp_val\"]\n",
    "            self.filter = to_load[\"filter\"]\n",
    "            self.scaler = to_load[\"scaler\"]\n",
    "            self.data_x = self.data\n",
    "            self.data_y = self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data reader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge_data = ForgingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preloaded_fdata= ForgingData(preload_path=\"/home/malio/EPICMAP/src/opcua/data/processed_forging_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, val_data1 = train_test_split(forge_data, test_size=0.2, random_state=42)\n",
    "data2, val_data2 = train_test_split(preloaded_fdata, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader1 = DataLoader(data1, batch_size=32, shuffle=False)\n",
    "val_loader1 = DataLoader(val_data1, batch_size=32, shuffle=False)\n",
    "train_loader2 = DataLoader(data2, batch_size=32, shuffle=False)\n",
    "val_loader2 = DataLoader(val_data2, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 384, 105]) torch.Size([32, 192, 105]) torch.Size([32, 384, 6]) torch.Size([32, 192, 6])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, x_mark, y_mark) in enumerate(train_loader1):\n",
    "    print(x.shape, y.shape, x_mark.shape, y_mark.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 384, 105]) torch.Size([32, 192, 105]) torch.Size([32, 384, 6]) torch.Size([32, 192, 6])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, x_mark, y_mark) in enumerate(train_loader2):\n",
    "    print(x.shape, y.shape, x_mark.shape, y_mark.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/timeseries_1month.csv\")\n",
    "data_val = pd.read_csv(\"../../data/timeseries.csv\")\n",
    "\n",
    "# forecasting task info\n",
    "seq_len = 24 * 4 * 4\n",
    "label_len = 24 * 4\n",
    "pred_len = 24 * 4\n",
    "data.drop_duplicates([\"Received Time\"], inplace=True, ignore_index=True)\n",
    "data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "data_val.drop_duplicates([\"Received Time\"], inplace=True, ignore_index=True)\n",
    "data_val = data_val.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Received Time\"] = pd.to_datetime(data[\"Received Time\"], format=\"ISO8601\")\n",
    "data = data.set_index(\"Received Time\")\n",
    "data = data.resample(\"100ms\").ffill()\n",
    "data.dropna(inplace=True)\n",
    "data = data.reset_index()\n",
    "\n",
    "data_val[\"Received Time\"] = pd.to_datetime(data_val[\"Received Time\"], format=\"ISO8601\")\n",
    "data_val = data_val.set_index(\"Received Time\")\n",
    "data_val = data_val.resample(\"100ms\").ffill()\n",
    "data_val.dropna(inplace=True)\n",
    "data_val = data_val.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time features\n",
    "data_stamp = time_features(pd.to_datetime(data[\"Received Time\"].values), freq=\"s\")\n",
    "data_stamp_val = time_features(pd.to_datetime(data_val[\"Received Time\"].values), freq=\"s\")\n",
    "data_stamp = data_stamp.transpose(1, 0)\n",
    "data_stamp_val = data_stamp_val.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = set()\n",
    "with open(\"/home/malio/EPICMAP/src/opcua/data_analysis/useless_counters.txt\", \"r\") as f:\n",
    "    to_filter = f.readline()\n",
    "    while to_filter:\n",
    "        filter.add(to_filter.rstrip())\n",
    "        to_filter = f.readline()\n",
    "\n",
    "data = data.drop(columns=filter, errors=\"ignore\")\n",
    "data_val = data_val.drop(columns=filter, errors=\"ignore\")\n",
    "\n",
    "data = data.drop(columns=[\"Received Time\"], errors=\"ignore\")\n",
    "data_val = data_val.drop(columns=[\"Received Time\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "# for testing\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "data_val = scaler.transform(data_val)\n",
    "data_x = data\n",
    "data_y = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path):\n",
    "    to_save = {}\n",
    "    to_save[\"data\"] = data\n",
    "    to_save[\"data_val\"] = data_val\n",
    "    to_save[\"data_stamp\"] = data_stamp\n",
    "    to_save[\"data_stamp_val\"] = data_stamp_val\n",
    "    to_save[\"filter\"] = filter\n",
    "    to_save[\"scaler\"] = scaler\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(to_save, f, protocol=4)\n",
    "\n",
    "def load(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        to_load = pickle.load(f)\n",
    "        data = to_load[\"data\"]\n",
    "        data_val = to_load[\"data_val\"]\n",
    "        data_stamp = to_load[\"data_stamp\"]\n",
    "        data_stamp_val = to_load[\"data_stamp_val\"]\n",
    "        filter = to_load[\"filter\"]\n",
    "        scaler = to_load[\"scaler\"]\n",
    "        data_x = data\n",
    "        data_y = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"./temp/save-data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32313748, 104), (32313748, 104), (32313748, 6), (6735215, 6))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape, data_stamp.shape, data_stamp_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"./temp/save-data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32313748, 104), (32313748, 104), (32313748, 6), (6735215, 6))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape, data_stamp.shape, data_stamp_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = ForgingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "serializing a string larger than 4 GiB requires pickle protocol 4 or higher",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../data/processed_forging_data.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EPICMAP/venv/lib/python3.10/site-packages/torch/serialization.py:652\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 652\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/EPICMAP/venv/lib/python3.10/site-packages/torch/serialization.py:864\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    862\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    863\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 864\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    866\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mOverflowError\u001b[0m: serializing a string larger than 4 GiB requires pickle protocol 4 or higher"
     ]
    }
   ],
   "source": [
    "fdata.save(\"../../data/processed_forging_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/processed_forging_data.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_loading_data \u001b[38;5;241m=\u001b[39m \u001b[43mForgingData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreload_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../data/processed_forging_data.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mForgingData.__init__\u001b[0;34m(self, preload_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preload_path:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreload_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/timeseries_1month.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 89\u001b[0m, in \u001b[0;36mForgingData.load\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     90\u001b[0m         to_load \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m to_load[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/EPICMAP/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/processed_forging_data.pt'"
     ]
    }
   ],
   "source": [
    "test_loading_data = ForgingData(preload_path=\"../../data/processed_forging_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'is_training': 1,\n",
    "    'task_id': 'test',\n",
    "    'model': 'FEDformer',\n",
    "    'version': 'Fourier',\n",
    "    'mode_select': 'random',\n",
    "    'modes': 64,\n",
    "    'L': 3,\n",
    "    'base': 'legendre',\n",
    "    'cross_activation': 'tanh',\n",
    "    'data': 'ETTh1',\n",
    "    'root_path': './dataset/ETT/',\n",
    "    'data_path': 'ETTh1.csv',\n",
    "    'features': 'M',\n",
    "    'target': 'OT',\n",
    "    'freq': 's',\n",
    "    'detail_freq': 'h',\n",
    "    'checkpoints': './checkpoints/',\n",
    "    'seq_len': 96,\n",
    "    'label_len': 96,\n",
    "    'pred_len': 96,\n",
    "    'enc_in': 105,\n",
    "    'dec_in': 105,\n",
    "    'c_out': 105,\n",
    "    'd_model': 512,\n",
    "    'n_heads': 8,\n",
    "    'e_layers': 2,\n",
    "    'd_layers': 1,\n",
    "    'd_ff': 2048,\n",
    "    'moving_avg': [12],\n",
    "    'factor': 1,\n",
    "    'distil': True,\n",
    "    'dropout': 0.05,\n",
    "    'embed': 'timeF',\n",
    "    'activation': 'gelu',\n",
    "    'output_attention': False,\n",
    "    'do_predict': False,\n",
    "    'num_workers': 10,\n",
    "    'itr': 3,\n",
    "    'train_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'patience': 3,\n",
    "    'learning_rate': 0.0001,\n",
    "    'des': 'test',\n",
    "    'loss': 'mse',\n",
    "    'lradj': 'type1',\n",
    "    'use_amp': False,\n",
    "    'use_gpu': True,\n",
    "    'gpu': 0,\n",
    "    'use_multi_gpu': True,\n",
    "    'devices': '1,2,3'\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, optim, device, criterion, epoch, train_steps, iter_count, scaler=None):\n",
    "    train_loss = []\n",
    "    time_now = time.time()\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "        iter_count += 1\n",
    "        optim.zero_grad()\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "        \n",
    "        # encoder - decoder\n",
    "        if args.use_amp:\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                if args.output_attention:\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if args.features == 'MS' else 0\n",
    "                batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                train_loss.append(loss.item())\n",
    "        else:\n",
    "            if args.output_attention:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if args.features == 'MS' else 0\n",
    "            batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
    "\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "            speed = (time.time() - time_now) / iter_count\n",
    "            left_time = speed * ((args.train_epochs - epoch) * train_steps - i)\n",
    "            print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            iter_count = 0\n",
    "            time_now = time.time()\n",
    "\n",
    "        # if args.use_amp:\n",
    "        #     scaler.scale(loss).backward()\n",
    "        #     scaler.step(optim)\n",
    "        #     scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(args, vali_data, vali_loader, criterion, model, device):\n",
    "        total_loss = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "                # encoder - decoder\n",
    "                if args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if args.output_attention:\n",
    "                            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if args.output_attention:\n",
    "                        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if args.features == 'MS' else 0\n",
    "                batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        model.train()\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(f\"cuda:{args.gpu}\" if args.use_gpu else \"cpu\")\n",
    "model = FEDformer.Model(args).to(device)\n",
    "model_optim = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data, val_ratio=0.2, random_seed=42):\n",
    "    \"\"\"\n",
    "    Splits a list of data into training and validation datasets.\n",
    "\n",
    "    Args:\n",
    "        data (list): The complete dataset to split.\n",
    "        val_ratio (float): The proportion of data to use for validation (default: 0.2).\n",
    "        random_seed (int): Random seed for reproducibility (default: 42).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two lists - training data and validation data.\n",
    "    \"\"\"\n",
    "    train_data, val_data = train_test_split(data, test_size=val_ratio, random_state=random_seed)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = split_data(fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [torch.as_tensor(cycle.astype(float).values) for cycle in cycles]\n",
    "# train_data, val_data = split_data(data, val_ratio=0.2)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m train_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m      4\u001b[0m iter_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cost time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m epoch_time))\n\u001b[1;32m      7\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(train_loss)\n",
      "Cell \u001b[0;32mIn[10], line 68\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, train_loader, model, optim, device, criterion, epoch, train_steps, iter_count, scaler)\u001b[0m\n\u001b[1;32m     61\u001b[0m     time_now \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# if args.use_amp:\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     scaler.scale(loss).backward()\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#     scaler.step(optim)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#     scaler.update()\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/EPICMAP/venv/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EPICMAP/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EPICMAP/venv/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.train_epochs):\n",
    "    epoch_time = time.time()\n",
    "    train_steps = len(train_loader)\n",
    "    iter_count = 0\n",
    "    train(args, train_loader, model, model_optim, device, criterion, epoch, train_steps, iter_count)\n",
    "    print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "    train_loss = np.average(train_loss)\n",
    "    vali_loss = validation(val_data, val_loader, criterion)\n",
    "    # test_loss = validation(test_data, test_loader, criterion)\n",
    "\n",
    "    print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f}\".format(\n",
    "        epoch + 1, train_steps, train_loss, vali_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
